

A collection of papers in performance evaluation.


### Involved Topics:
- Transferability Estimation
- Model/Dataset Vectorization
- Model/Algorithm/Representation Evaluation
- Generalization Gap Prediction
- Out-of-distribution Error Prediction
- Accuracy Prediction
- Model Validation
- Calibration Error Prediction
- Confidence Calibration
----
### Survey
- A Survey on Evaluation of Out-of-Distribution Generalization [[Paper]](https://arxiv.org/pdf/2403.01874)
- Which Model to Transfer? A Survey on Transferability Estimation [[Paper]](https://arxiv.org/pdf/2402.15231.pdf)
-  A Survey of Language Model Confidence Estimation and Calibration [[Paper]](https://arxiv.org/abs/2311.08298)
-  Calibration of Neural Networks [[Paper]](https://arxiv.org/abs/2303.10761)
---
### 2024
- Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress [[Paper]](https://arxiv.org/pdf/2402.19472.pdf)
- Energy-based Automated Model Evaluation [[Paper]](http://arxiv.org/abs/2401.12689)
- Rethinking The Uniformity Metric in Self-Supervised Learning [[Paper]](http://arxiv.org/abs/2403.00642)
- Revisiting Disentanglement in Downstream Tasks: A Study on Its Necessity for Abstract Visual Reasoning [[Paper]](https://arxiv.org/pdf/2403.00352.pdf)
- Revisiting Confidence Estimation: Towards Reliable Failure Prediction [[TPAMI]](https://arxiv.org/pdf/2403.02886.pdf) [[Code]](https://github.com/Impression2805/FMFP)
	- Conference ver. :  Rethinking Confidence Calibration for Failure Prediction [[ECCV22]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850512.pdf)
- Tune without Validation: Searching for Learning Rate and Weight Decay on Training Sets [[Paper]](https://arxiv.org/pdf/2403.05532.pdf)

### 2023
- Unsupervised Accuracy Estimation of Deep Visual Models using Domain-Adaptive Adversarial Perturbation without Source Samples [[ArXiv]](https://arxiv.org/pdf/2307.10062.pdf)
- K-Means Clustering Based Feature Consistency Alignment for Label-Free Model Evaluation [[CVPR Workshop]](https://openaccess.thecvf.com/content/CVPR2023W/VDU/html/Miao_K-Means_Clustering_Based_Feature_Consistency_Alignment_for_Label-Free_Model_Evaluation_CVPRW_2023_paper.html)
- Predicting Out-of-Domain Generalization with Neighborhood Invariance [[TMLR]](https://openreview.net/forum?id=jYkWdJzTwn)
- Test Accuracy vs. Generalization Gap: Model Selection in NLP without Accessing Training or Testing Data [[SIGKDD]](https://dl.acm.org/doi/abs/10.1145/3580305.3599518)
- Analysis of Task Transferability in Large Pre-trained Classifiers [[Under Review]](https://openreview.net/forum?id=HCMmC8DETj)
- A Bag-of-Prototypes Representation for Dataset-Level Applications [[CVPR]](https://openaccess.thecvf.com/content/CVPR2023/html/Tu_A_Bag-of-Prototypes_Representation_for_Dataset-Level_Applications_CVPR_2023_paper.html)
- DataMap: Dataset transferability map for medical image classification [[PR]](https://www.sciencedirect.com/science/article/abs/pii/S0031320323007410)
- To transfer or not transfer: Unified transferability metric and analysis [[ArXiv]](https://arxiv.org/abs/2305.07741)
- Quantifying the impact of data characteristics on the transferability of sleep stage scoring models [[Artificial Intelligence in Medicine Xiv]](https://www.sciencedirect.com/science/article/pii/S0933365723000544)
- Identification of Negative Transfers in Multitask Learning Using Surrogate Models [[TMLRArXiv]](https://arxiv.org/abs/2303.14582)
- Quantifying the impact of data characteristics on the transferability of sleep stage scoring models [[AIM]](https://www.sciencedirect.com/science/article/pii/S0933365723000544?ssrnid=4142311&dgcid=SSRN_redirect_SD)
- Model selection, adaptation, and combination for transfer learning in wind and photovoltaic power forecasts [[Energy and AI]](https://www.sciencedirect.com/science/article/pii/S2666546823000216)
- Identifying Useful Learnwares for Heterogeneous Label Spaces [[ICML]](https://proceedings.mlr.press/v202/guo23l/guo23l.pdf)
- Transferability prediction among classification and regression tasks using optimal transport [[Multimedia Tools and Applications]](https://link.springer.com/article/10.1007/s11042-023-15852-6)
- Choosing public datasets for private machine learning via gradient subspace distance[[Paper]](https://arxiv.org/abs/2303.01256)
- Learning to Predict Task Transferability via Soft Prompt[[Paper]](https://aclanthology.org/2023.emnlp-main.546/)
- Understanding Few-Shot Learning: Measuring Task Relatedness and Adaptation Difficulty via Attributes[[Paper]](https://openreview.net/forum?id=Pvgxecj5aS)
- Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach [[ICCV]](https://arxiv.org/abs/2309.02429)
- How to Estimate Model Transferability of Pre-Trained Speech Models? [[InterSpeech]](https://arxiv.org/abs/2306.01015)
- TaskWeb: Selecting Better Source Tasks for Multi-task NLP[[Paper]](https://arxiv.org/abs/2305.13256
- Feasibility and Transferability of Transfer Learning: A Mathematical Framework [[ArXiv]](https://arxiv.org/abs/2301.11542)
- Topological Vanilla Transfer Learning [[Paper]](https://openreview.net/forum?id=3kK8x_92hnD)
-  Model Spider: Learning to Rank Pre-Trained Models Efficiently [[Arxiv]](https://arxiv.org/abs/2306.03900)
-  Towards Estimating Transferability using Hard Subsets [[ArXiv]](https://arxiv.org/abs/2301.06928)
- Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation [[MICCAI]](https://arxiv.org/pdf/2307.11958.pdf)
-  Simple Transferability Estimation for Regression Tasks [[UAI]](https://proceedings.mlr.press/v216/nguyen23a.html)
-  Transferability Metrics for Object Detection [[ArXiv]](https://arxiv.org/abs/2306.15306)
- Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance[[ArXiv]](https://arxiv.org/pdf/2308.05986.pdf)
- ETran: Energy-Based Transferability Estimation [[ICCV]](https://openaccess.thecvf.com/content/ICCV2023/html/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.html)
- How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability [[ICCV]](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.html)
- Exploring Model Transferability through the Lens of Potential Energy[[ICCV]](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.html)
- Unleashing the power of Neural Collapse for Transferability Estimation [[ArXiv]](https://arxiv.org/abs/2310.05754)
- Foundation Model is Efficient Multimodal Mltitask Model Selector [[ArXiv]](https://arxiv.org/abs/2308.06262)
- **?**[multi-model] Towards Robust Multi-Modal Reasoning via Model Selection [[ArXiv]](https://arxiv.org/abs/2310.08446)
- Graph-based fine-grained model selection for multi-source domain [[PAA]](https://link.springer.com/article/10.1007/s10044-023-01176-6)
- Guided Recommendation for Model Fine-Tuning [[CVPR]](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Guided_Recommendation_for_Model_Fine-Tuning_CVPR_2023_paper.html)
- Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How [[ArXiv]](https://arxiv.org/abs/2306.03828)
- Estimating the Transfer Learning Ability of a Deep Neural Networks by Means of Representations [[NCMLCR]](https://link.springer.com/chapter/10.1007/978-3-031-44865-2_50)
-  Source Selection based on Diversity for Machine Learning [[Patent ]](https://www.freepatentsonline.com/20230316134.pdf)
- Efficient Prediction of Model Transferability in Semantic Segmentation Tasks [[ICIP]](https://ieeexplore.ieee.org/abstract/document/10222912)
-  The Performance of Transferability Metrics Does Not Translate to Medical Tasks [[MICCAI workshop]](https://link.springer.com/chapter/10.1007/978-3-031-45857-6_11)
- How to Estimate Model Transferability of Pre-Trained Speech Models? [[Interspeech]](https://arxiv.org/abs/2306.01015)
- How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey [[ArXiv]](https://arxiv.org/pdf/2312.04775.pdf)
- Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach [[ICCV]](https://openaccess.thecvf.com/content/ICCV2023/html/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.html)
- Guided recommendation for model fine-tuning[[Paper]](http://openaccess.thecvf.com/content/CVPR2023/html/Li_Guided_Recommendation_for_Model_Fine-Tuning_CVPR_2023_paper.html)
- LOVM: Language-Only Vision Model Selection [[NeurIPSW]](https://arxiv.org/abs/2306.08893)
- RankMe: Assessing the Downstream Performance of Pretrained Self-Supervised Representations by Their Rank [[ICML Oral]](https://openreview.net/forum?id=neTWpgvVbo)
-  T-Measure: A Measure for Model Transferabilty [[Under Review]](https://openreview.net/forum?id=gLtHsY0zCC)
- Using Representation Expressiveness and Learnability to Evaluate Self-Supervised Learning Methods [[TMLR]](https://openreview.net/pdf?id=BxdrpnRHNh)
- Domain Adaptation for Network Performance Modeling with and without Labeled Data [[NOMS]](https://ieeexplore.ieee.org/abstract/document/10154428)
- Content-Based Search for Deep Generative Models [[ArXiv]](https://arxiv.org/pdf/2210.03116.pdf)
-  GNNEvaluator: Evaluating GNN Performance On Unseen Graphs Without Labels [[NeurIPS]](https://arxiv.org/pdf/2310.14586.pdf)
- Learning inter-task transferability in the absence of target  task samples[[Paper]](https://www.cs.utexas.edu/~pstone/Papers/bib2html-links/AAMAS15-sinapov.pdf) 
- Model selection for cross-lingual transfer[[Paper]](https://arxiv.org/abs/2010.06127)
- ModelGiF: Gradient Fields for Model Functional Distance[[Paper]](https://github.com/zju-vipa/modelgif)
- Predicting Out-of-Distribution Error with Confidence Optimal Transport [[Paper]](http://arxiv.org/abs/2302.05018)
- Gnnevaluator: Evaluating gnn performance on unseen graphs without labels [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/6a55f024db3f771194bdadc8f3a35381-Abstract-Conference.html)
- Came: Contrastive automated model evaluation [[ICCV]](http://openaccess.thecvf.com/content/ICCV2023/html/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.html) 
-  On the Importance of Feature Separability in Predicting Out-Of-Distribution Error [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2023/file/585e9cf25585612ac27b535457116513-Paper-Conference.pdf)
- Characterizing out-of-distribution error via optimal transport [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/38fd51cf36f28566230a93a5fbeaabbf-Abstract-Conference.html)
- What can we Learn by Predicting Accuracy? [[WACV]](https://openaccess.thecvf.com/content/WACV2023/html/Risser-Maroix_What_Can_We_Learn_by_Predicting_Accuracy_WACV_2023_paper.html)
- Cifar-10-warehouse: Broad and more realistic testbeds in model generalization analysis [[Paper]](https://arxiv.org/abs/2310.04414)

### 2022
- On the Relationship Between Explanation and Prediction: A Causal View [[ArXiv]](https://arxiv.org/abs/2212.06925)
- The Missing Margin: How Sample Corruption Affects Distance to the Boundary in ANNs [[AIR]](https://link.springer.com/chapter/10.1007/978-3-031-22321-1_6)
- Generalization Bounds for Deep Transfer Learning Using Majority Predictor Accuracy [[ISITA]](https://arxiv.org/abs/2209.05709)
- Transferability Estimation Based On Principal Gradient Expectation [[ArXiv]](http://arxiv.org/abs/2211.16299)
- Transferability-Guided Cross-Domain Cross-Task Transfer Learning [[ArXiv]](https://arxiv.org/abs/2207.05510)
- Wasserstein Task Embedding for Measuring Task Similarities [[ArXiv]](https://arxiv.org/abs/2208.11726)[[Code]](https://github.com/xinranliueva/Wasserstein-Task-Embedding)
- Efficiently tuned parameters are task embeddings[[Paper]](https://arxiv.org/abs/2210.11705)
- Fisher task distance and its application in neural architecture search[[Paper]](https://ieeexplore.ieee.org/abstract/document/9766163/)
- Leveraging task transferability to meta-learning for clinical section classification with limited data[[Paper]](https://aclanthology.org/2022.acl-long.461/)
- Transferability Between Regression Tasks[[Paper]](https://openreview.net/forum?id=LB6KMRUqng2)
- Dataset2vec: Learning dataset meta-features[[Paper]](https://link.springer.com/article/10.1007/s10618-021-00737-9)
- CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in  NLP[[ACL]](https://aclanthology.org/2022.acl-long.64.pdf)
- Exploring the role of task transferability in large-scale multi-task learning[[Paper]](https://arxiv.org/abs/2204.11117)
- Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance [[ECML PKDD]](https://arxiv.org/abs/2110.06893)
- Frustratingly Easy Transferability Estimation [[ICML]](https://proceedings.mlr.press/v162/huang22d.html) [[Slides]](https://icml.cc/media/icml-2022/Slides/17386.pdf)
- Transferability Estimation Using Bhattacharyya Class Separability [[CVPR]](https://openaccess.thecvf.com/content/CVPR2022/html/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.html)
- Transferability Metrics for Selecting Source Model Ensembles [[CVPR]](https://openaccess.thecvf.com/content/CVPR2022/papers/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.pdf)
-  How stable are Transferability Metrics evaluations? [[ECCV]](https://arxiv.org/abs/2204.01403) [[TensorFlow]](https://github.com/google-research/google-research/tree/master/stable_transfer)
- Pre-Trained Model Reusability Evaluation for Small-Data Transfer Learning [[NeurIPS]](https://openreview.net/forum?id=XY5g3mkVge) [[Codes]](https://github.com/candytalking/SynLearn.)
- Neural Transferability: Current Pitfalls and Striving for Optimal Scores [[Paper]](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4196999)
- Ranking and Tuning Pre-trained Models: A New Paradigm for Exploiting Model Hubs [[JMLR]](https://www.jmlr.org/papers/volume23/21-1251/21-1251.pdf)
- PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks [[ECCV]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136940244.pdf) [[Codes]](https://github.com/google-research/pactran_metrics)
-  Which Model to Transfer? Finding the Needle in the Growing Haystack [[CVPR]](https://openaccess.thecvf.com/content/CVPR2022/html/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.html)
- Evidence > Intuition: Transferability Estimation for Encoder Selection [[EMNLP]](https://arxiv.org/abs/2210.11255)
- Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space [[ECCV]](https://link.springer.com/chapter/10.1007/978-3-031-19830-4_17)
- Efficient Semantic Segmentation Backbone Evaluation for Unmanned Surface Vehicles based on Likelihood Distribution Estimation [[MSN]](https://ieeexplore.ieee.org/abstract/document/10076662)
- ZooD: Exploiting Model Zoo for Out-of-Distribution Generalization [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/cd305fdee96836d5cc1de94577d71b61-Abstract-Conference.html)
- Pre-Trained Model Reusability Evaluation for Small-Data Transfer Learning [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/f308b5f207348484552997c536375654-Abstract-Conference.html)
- Predicting Out-of-Distribution Error with the Projection Norm [[paper]](http://arxiv.org/abs/2202.05834)
- Agreement-on-the-line: Predicting the performance of neural networks under distribution shift [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/file/7a8d388b7a17df480856dff1cc079b08-Paper-Conference.pdf)
- Leveraging unlabeled data to predict out-of-distribution performance [[Paper]](https://arxiv.org/abs/2201.04234)
- Estimating and Explaining Model Performance When Both Covariates and Labels Shift [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/file/4aa13186c795a52ba88f5b822f4b77eb-Paper-Conference.pdf)
- Unsupervised and semi-supervised bias benchmarking in face recognition [[ECCV]](https://link.springer.com/chapter/10.1007/978-3-031-19778-9_17)
- On the strong correlation between model invariance and generalization [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b3847cda0c8cc0cfcdacf462dc122214-Abstract-Conference.html)
- Active surrogate estimators: An active learning approach to label-efficient model evaluation [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9b9cfd5428153ccfbd4ba34b7e007305-Abstract-Conference.html)
- Predicting out-of-domain generalization with local manifold smoothness [[Paper]](https://arxiv.org/abs/2207.02093)

### 2021
- A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning [[NeurIPS]](https://proceedings.neurips.cc/paper/2021/hash/db9ad56c71619aeed9723314d1456037-Abstract.html)
- Transferability Estimation for Semantic Segmentation Task [[]](https://arxiv.org/abs/2109.15242)
- OTCE: A Transferability Metric for Cross-Domain Cross-Task Representations [[CVPR]](https://openaccess.thecvf.com/content/CVPR2021/papers/Tan_OTCE_A_Transferability_Metric_for_Cross-Domain_Cross-Task_Representations_CVPR_2021_paper.pdf) [[Poster]](https://www.tbsi.edu.cn/wolt/tbsi_wolt2020/posters/tanyang.pdf)
- Practical Transferability Estimation for Image Classification Tasks [[ArXiv]](https://arxiv.org/abs/2106.10479)
- What to pre-train on? efficient intermediate task selection [[EMNLP]](https://arxiv.org/abs/2104.08247)
- Efficiently identifying task groupings for multi-task learning[[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2021/hash/e77910ebb93b511588557806310f78f1-Abstract.html)
- The information complexity of learning tasks, their structure and their distance[[Paper]](https://academic.oup.com/imaiai/article-abstract/10/1/51/6059450)
- An information-geometric distance on the space of tasks](https://proceedings.mlr.press/v139/gao21a.html)
- [ImageDataset2Vec: An image dataset embedding for algorithm selection[[Paper]](https://www.sciencedirect.com/science/article/pii/S0957417421004942)
-  Similarity of classification tasks[[Paper]](https://arxiv.org/abs/2101.11201)
- Cats, not CAT scans: a study of dataset similarity in transfer learning for 2D medical image classification[[Paper]](https://arxiv.org/abs/2107.05940)
- Analysis and Prediction of NLP models via Task Embeddings[[Paper]](https://arxiv.org/abs/2112.05647)
- Inter-task similarity measure for heterogeneous  tasks[[Paper]](https://link.springer.com/chapter/10.1007/978-3-030-98682-7_4)
- Ranking Neural Checkpoints [[CVPR]](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Ranking_Neural_Checkpoints_CVPR_2021_paper.pdf)
- LogME: Practical Assessment of Pre-trained Models for Transfer Learning [[ICML]](https://arxiv.org/abs/2102.11005) [[PyTorch]](https://github.com/thuml/LogME)
-  Scalable Diverse Model Selection for Accessible Transfer Learning [[NeurIPS]](https://proceedings.neurips.cc/paper/2021/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf) [[PyTorch]](https://github.com/dbolya/parc)
- A linearized framework and a new benchmark for model selection for fine-tuning [[ArXiv]](https://arxiv.org/pdf/2102.00084.pdf)
- Are Labels Always Necessary for Classifier Accuracy Evaluation? [[ICCV]](https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Are_Labels_Always_Necessary_for_Classifier_Accuracy_Evaluation_CVPR_2021_paper.pdf)
- Predicting With Confidence on Unseen Distributions [[ICCV]](https://openaccess.thecvf.com/content/ICCV2021/papers/Guillory_Predicting_With_Confidence_on_Unseen_Distributions_ICCV_2021_paper.pdf)
- What does rotation prediction tell us about classifier accuracy under varying testing environments?[[ICML]](https://proceedings.mlr.press/v139/deng21a.html)
- Detecting errors and estimating accuracy on unlabeled data with self-training ensembles[[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2021/hash/7dd3ed2e12d7967b656d156d50308263-Abstract.html)
- Ranking models in unlabeled new environments [[ICCV]](http://openaccess.thecvf.com/content/ICCV2021/html/Sun_Ranking_Models_in_Unlabeled_New_Environments_ICCV_2021_paper.html)

### 2020
- Duality diagram similarity: a generic framework for initialization selection in task transfer learning [[ECCV]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710494.pdf)
- Exploring and Predicting Transferability across NLP Tasks [[EMNLP]](https://arxiv.org/abs/2005.00770)
- Geometric Dataset Distances via Optimal Transport [[NeurIPS]](https://proceedings.neurips.cc/paper/2020/hash/f52a7b2610fb4d3f74b4106fb80b233d-Abstract.html)
- Similarity of neural networks with gradients[[Paper]](https://arxiv.org/abs/2003.11498)
- Measuring and Harnessing Transference in Multi-Task Learning [[Ar]](https://arxiv.org/abs/2010.15413)
- LEEP: A New Measure to Evaluate Transferability of Learned Representations [[ICML]](https://arxiv.org/pdf/2002.12462) [[Slides]](https://dev.icml.cc/media/icml-2020/Slides/6289.pdf) [[PyTorch]](https://github.com/thuml/LogME)
- Source Model Selection for Deep Learning in the Time Series Domain [[IEEE Access]](https://ieeexplore.ieee.org/document/8949507)
- [Ranking and rejecting of pre-trained deep neural networks in transfer learning based on separation index][[ArXiv]](https://arxiv.org/abs/2012.13717)
- DEPARA: Deep Attribution Graph for Deep Knowledge Transferability [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Song_DEPARA_Deep_Attribution_Graph_for_Deep_Knowledge_Transferability_CVPR_2020_paper.pdf)
-  Predicting neural network accuracy from weight [[Paper]](https://arxiv.org/pdf/2002.11448)
- Computing the testing error without a testing set [[CVPR]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Corneanu_Computing_the_Testing_Error_Without_a_Testing_Set_CVPR_2020_paper.pdf)
- Fantastic generalization measures and where to find them [[ICLR]](https://arxiv.org/abs/1912.02178)

### 2019
- TASK2VEC: Task Embedding for Meta-Learning [[ICCV]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Achille_Task2Vec_Task_Embedding_for_Meta-Learning_ICCV_2019_paper.pdf)
- Finding the Most Transferable Tasks for Brain Image Segmentation [[BIBM]](https://ieeelorieee.org/plconhe/79/proceeding)
- aserstein Task Ebei for Measring Tas imilaitis [[ArXiv]](https://arxiv.org/abs/2301.00934) 0.17)
- Zero-Shot Task Transfer
-  Transferability and Hardness of Supervised Classification Tasks [[ICCV]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Tran_Transferability_and_Hardness_of_Supervised_Classification_Tasks_ICCV_2019_paper.pdf) 
-  An informationtheoretic approach to transferability in task transfer learning [[ICIP]](https://ieeexplore.ieee.org/document/8803726) [[Codes]](https://github.com/YaojieBao/An-Information-theoretic-Metric-of-Transferability)
-  Model reuse with reduced kernel mean embedding specification [[ArXiv]](https://arxiv.org/abs/2001.07135)
- TASK2VEC: Task Embedding for Meta-Learning [[ICCV]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Achille_Task2Vec_Task_Embedding_for_Meta-Learning_ICCV_2019_paper.pdf)
- Service Metric Prediction in Clouds using Transfer Learning [[DiVA]](https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1368298&dswid=3495)
- Predicting the Generalization Gap in Deep Networks with Margin Distributions [[ICLR]](http://arxiv.org/abs/1810.00113)

### 2018
- Taskonomy: Disentangling Task Transfer Learning [[CVPR Best Paper]](https://arxiv.org/abs/1804.08328)
- Dynamics and reachability of learning tasks[[Paper]](https://arxiv.org/abs/1810.02440)
- Stronger generalization bounds for deep nets via a compression approach [[ICML]](http://proceedings.mlr.press/v80/arora18b/arora18b.pdf)

### 2017
-  Exploring generalization in deep learning [[NeurIPS]](http://papers.neurips.cc/paper/7176-exploring-generalization-in-deep-learning.pdf)
- Estimating accuracy from unlabeled data: A probabilistic logic approach [[NeurIPS]](http://papers.neurips.cc/paper/7023-estimating-accuracy-from-unlabeled-data-a-probabilistic-logic-approach.pdf)

### 2016
- Learning to Select Pre-trained Deep Representations with Bayesian Evidence Framework [[CVPR]](https://openaccess.thecvf.com/content_cvpr_2016/papers/Kim_Learning_to_Select_CVPR_2016_paper.pdf)
- Learning with rejection [[Paper]](https://cs.nyu.edu/~mohri/pub/rej.pdf)
- Estimating accuracy from unlabeled data: A bayesian approach [[ICML]](https://proceedings.mlr.press/v48/platanios16.html)

### 2004
- Using model disagreement on unlabeled data to validate classification algorithms [[NeurIPS]](https://proceedings.neurips.cc/paper_files/paper/2004/file/92f54963fc39a9d87c2253186808ea61-Paper.pdf)

